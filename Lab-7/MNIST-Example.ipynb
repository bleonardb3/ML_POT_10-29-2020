{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras to recognize hand-written digits with `ibm-watson-machine-learning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains steps and code to demonstrate support of Deep Learning experiments in the Watson Machine Learning service. It introduces commands for data retrieval, training definition persistance, experiment training, model persistance, and model deployment. \n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.7.\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Working with the Watson Machine Learning service.\n",
    "-  Training Deep Learning models (Keras - TensorFlow).\n",
    "-  Saving trained models in Watson Machine Learning repository.\n",
    "-  Online deployment of the trained model.\n",
    "-  Scoring two samples\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Setup](#setup)\n",
    "2.\t[Create model definition](#model_df)\n",
    "3.\t[Train model](#training)\n",
    "4.  [Persist trained model](#persist)\n",
    "5.\t[Deploy and Score](#deploy)\n",
    "6.  [Clean up](#clean)\n",
    "7.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Working with Cloud Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ibm_boto3` library allows Python developers to manage Cloud Object Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If `ibm_boto3` is not preinstalled in you environment please install it by running the following command: `!pip install ibm-cos-sdk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Paste your COS credentials in the following cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_credentials = PASTE CREDENTIALS HERE    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action**: Paste your service endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint = \"https://PASTE SERVICE ENDPOINT HERE\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Boto resource by providing type, endpoint_url and credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = ibm_boto3.resource('s3',\n",
    "                         ibm_api_key_id=cos_credentials[\"apikey\"],\n",
    "                         ibm_service_instance_id=cos_credentials[\"resource_instance_id\"],\n",
    "                         ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "                         config=Config(signature_version='oauth'),\n",
    "                         endpoint_url=service_endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the buckets that you will use to store training data and training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**: Bucket name has to be unique - please update following ones to any unique name.<br>\n",
    "Replace xxx with your initials below in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = ['tf-keras-data-example-xxx', 'tf-keras-results-example-xxx']\n",
    "for bucket in buckets:\n",
    "    if not cos.Bucket(bucket) in cos.buckets.all():\n",
    "        print('Creating bucket \"{}\"...'.format(bucket))\n",
    "        try:\n",
    "            cos.create_bucket(Bucket=bucket)\n",
    "        except ibm_boto3.exceptions.ibm_botocore.client.ClientError as e:\n",
    "            print('Error: {}.'.format(e.response['Error']['Message']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buckets are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(cos.buckets.limit(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download the MNIST data and upload it to the COS bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we work with the Keras **MNIST** sample dataset. Download the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell creates the 'MNIST_KERAS_DATA' folder and downloads the file from link.\n",
    "\n",
    "**Note:** First install `wget` library by the following command\n",
    "`!pip install wget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://s3.amazonaws.com/img-datasets/mnist.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "\n",
    "data_dir = 'MNIST_KERAS_DATA'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "if not os.path.isfile(os.path.join(data_dir, os.path.join(link.split('/')[-1]))):\n",
    "    wget.download(link, out=data_dir)  \n",
    "        \n",
    "!ls MNIST_KERAS_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now upload the training data to the bucket assigned for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = buckets[0]\n",
    "bucket_obj = cos.Bucket(bucket_name)\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, filename), 'rb') as data: \n",
    "        bucket_obj.upload_file(os.path.join(data_dir, filename), filename)\n",
    "        print('{} is uploaded.'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the list of objects in the training bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in bucket_obj.objects.all():\n",
    "    print('Object key: {}'.format(obj.key))\n",
    "    print('Object size (kb): {}'.format(obj.size/1024))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Connection to WML\n",
    "\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud. You need to provide the platform `api_key` and instance `location`.\n",
    "\n",
    "Refer to the Lab-5 notebook (Heart Disease) to get the api key and location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'PASTE API KEY HERE'\n",
    "location = 'PASTE LOCATION HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import the `ibm-watson-machine-learning` package\n",
    "**Note:** `ibm-watson-machine-learning` documentation can be found <a href=\"http://ibm-wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with spaces\n",
    "\n",
    "We created a deployment space in Lab-1. The code below provides a list\n",
    "of deployment spaces. The space_id is obtained from the ID column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the value in the ID column that corresponds to the Watson Studio Labs deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_id = \"PASTE SPACE ID HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to interact with all resources available in Watson Machine Learning, you need to set the **space** which you will be using.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_def\"></a>\n",
    "# 2. Create model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this example two Keras model definitions have been prepared:\n",
    "\n",
    " - Multilayer Perceptron (MLP)\n",
    " - Convolution Neural Network (CNN)\n",
    " \n",
    "We will train the Convolution Neural Network below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare model definition metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaprops = {\n",
    "    client.model_definitions.ConfigurationMetaNames.NAME: \"MNIST cnn model definition\",\n",
    "    client.model_definitions.ConfigurationMetaNames.DESCRIPTION: \"MNIST cnn model definition\",\n",
    "    client.model_definitions.ConfigurationMetaNames.COMMAND: \"python3 mnist_cnn.py --trainImagesFile ${DATA_DIR}/train-images-idx3-ubyte.gz --trainLabelsFile ${DATA_DIR}/train-labels-idx1-ubyte.gz --testImagesFile ${DATA_DIR}/t10k-images-idx3-ubyte.gz --testLabelsFile ${DATA_DIR}/t10k-labels-idx1-ubyte.gz --learningRate 0.001 --trainingIters 6000\",\n",
    "    client.model_definitions.ConfigurationMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.6\"]},\n",
    "    client.model_definitions.ConfigurationMetaNames.VERSION: \"2.0\",\n",
    "    client.model_definitions.ConfigurationMetaNames.SPACE_UID: space_id\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get sample model definition content files from git (Python scripts with CNN and MLP)\n",
    "\n",
    "The MNIST.zip file contains 3 python files (1) multilayer perceptron model, (2) convolution neural network model, (3) metrics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mnist = 'MNIST.zip'\n",
    "\n",
    "if not os.path.isfile(filename_mnist):\n",
    "    filename_mnist = wget.download('https://github.com/IBM/watson-machine-learning-samples/raw/master/definitions/keras/mnist/MNIST.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Publish model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition_details = client.model_definitions.store(filename_mnist, meta_props=metaprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_definition_id = client.model_definitions.get_id(model_definition_details)\n",
    "print(model_definition_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.model_definitions.list(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare training metadata\n",
    "\n",
    "The code below provides a training manifest that is used by the Watson Machine Learning service to create the environment to run the neural network training. The training data bucket, the results bucket, the command to run the Keras model, and the environment is specified. This is referred to as a training definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = {\n",
    "    client.training.ConfigurationMetaNames.NAME: \"Keras-MNIST\",\n",
    "    client.training.ConfigurationMetaNames.SPACE_UID: space_id,\n",
    "    client.training.ConfigurationMetaNames.DESCRIPTION: \"Keras-MNIST predict written digits\",\n",
    "    client.training.ConfigurationMetaNames.TAGS :[{\n",
    "      \"value\": \"MNIST\",\n",
    "      \"description\": \"predict written digits\"\n",
    "    }],\n",
    "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE:  {\n",
    "    \"name\": \"MNIST results\",\n",
    "    \"connection\": {\n",
    "            \"endpoint_url\": service_endpoint,\n",
    "            \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "            \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      },\n",
    "      \"location\": {\n",
    "        \"bucket\": buckets[0]\n",
    "      },\n",
    "    \"type\": \"s3\"\n",
    "  },\n",
    "  client.training.ConfigurationMetaNames.MODEL_DEFINITION:{\n",
    "        \"id\": model_definition_id,\n",
    "        \"command\": \"python3 mnist_cnn.py --trainImagesFile ${DATA_DIR}/train-images-idx3-ubyte.gz --trainLabelsFile ${DATA_DIR}/train-labels-idx1-ubyte.gz --testImagesFile ${DATA_DIR}/t10k-images-idx3-ubyte.gz --testLabelsFile ${DATA_DIR}/t10k-labels-idx1-ubyte.gz --learningRate 0.001 --trainingIters 6000\",\n",
    "        \"hardware_spec\": {\n",
    "          \"name\": \"K80\",\n",
    "          \"nodes\": 1\n",
    "        },\n",
    "        \"software_spec\": {\n",
    "          \"name\": \"tensorflow_1.15-py3.6\"\n",
    "        },\n",
    "        \"parameters\": {\n",
    "          \"name\": \"MNIST cnn\",\n",
    "          \"description\": \"Simple MNIST cnn model\"\n",
    "        }\n",
    "      },\n",
    "  client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: [\n",
    "       {\n",
    "      \"name\": \"training_input_data\",\n",
    "      \"type\": \"s3\",\n",
    "      \"connection\": {\n",
    "        \"endpoint_url\": service_endpoint,\n",
    "        \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "        \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      },\n",
    "      \"location\": {\n",
    "        \"bucket\": buckets[1]\n",
    "      },\n",
    "      \"schema\": {\n",
    "        \"id\":\"idcnn_schema\",\n",
    "        \"fields\": [\n",
    "          {\n",
    "            \"name\": \"text\",\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train model in background\n",
    "\n",
    "Submit the training run to the Watson Machine Learning Service. This is an asynchronous call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = client.training.run(training_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Get training id and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = client.training.get_uid(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will needed to repeatedly execute the following code to monitor the status of the training process. The status should go from pending, to running, to completed. Don't proceed with the notebook until you have a status of completed. It should take about 5 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.training.get_status(training_id)[\"state\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Get training details\n",
    "\n",
    "After executing the code in the next cell, scroll down until you see ml_metrics;  you should see ml_metrics listed 4 times. \n",
    "The accuracy of the training run corresponds to the 4th ml_metrics listed. It should be 98.1% accuracy on training and 98.85% accuracy on the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_details = client.training.get_details(training_id)\n",
    "print(json.dumps(training_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.training.list(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancel training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can cancel the training run by calling the method below. Otherwise skip past it. \n",
    "**Tip**: If you want to delete train runs and results add `hard_delete=True` as a parameter."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.training.cancel(training_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persist\"></a>\n",
    "# 4. Persist trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Download trained model from COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = client.training.get_details(training_id)['entity']['results_reference']['location']['logs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download model from COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = buckets[0]\n",
    "bucket_obj = cos.Bucket(bucket_name)\n",
    "\n",
    "model_path = \"\"\n",
    "for obj in bucket_obj.objects.iterator():\n",
    "    if uid in obj.key and obj.key.endswith(\".h5\"):\n",
    "        model_path = obj.key\n",
    "        break\n",
    "\n",
    "model_name = model_path.split(\"/\")[-1]\n",
    "bucket_obj.download_file(model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpack model and compress it to tar.gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "    \n",
    "model_name = \"mnist_cnn.h5\"    \n",
    "with tarfile.open(model_name + \".tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"mnist_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Publish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name('tensorflow_1.15-py3.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta_props = {\n",
    "                    client.repository.ModelMetaNames.NAME: \"Keras MNIST\",\n",
    "                    client.repository.ModelMetaNames.TYPE: \"keras_2.2.5\",\n",
    "                    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "published_model = client.repository.store_model(model='mnist_cnn.h5.tar.gz', meta_props=model_meta_props)\n",
    "model_uid = client.repository.get_model_uid(published_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Get model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.get_details(model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List stored models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.list_models(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "# 5. Deploy and score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create online deployment for published model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = client.deployments.create(model_uid, meta_props={\n",
    "                                            client.deployments.ConfigurationMetaNames.NAME: \"Keras MNIST\",\n",
    "                                            client.deployments.ConfigurationMetaNames.ONLINE: {}})\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get deployments details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments_details = client.deployments.get_details(deployment_uid)\n",
    "print(json.dumps(deployments_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.list(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Score deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot two digits. **Action:** Please install `matplotlib`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "dataset_filename='mnist.npz'\n",
    "\n",
    "if not os.path.isfile(dataset_filename):\n",
    "    dataset_filename = wget.download('https://github.com/IBM/watson-machine-learning-samples/raw/master/data/mnist/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mnist_dataset = np.load(dataset_filename)\n",
    "x_test = mnist_dataset['x_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate([x_test[0], x_test[1]]):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input node expects to get data with shape (28,28,1) so we need to reshape our two digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = x_test[0]/ 255\n",
    "image_2 = x_test[1]/ 255\n",
    "image_1 = image_1.reshape(28,28,1)\n",
    "image_2 = image_2.reshape(28,28,1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare scoring payload and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA : [\n",
    "        {'values': [image_1.tolist(), image_2.tolist()]}\n",
    "    ]\n",
    "}\n",
    "scores = client.deployments.score(deployment_uid, meta_props=scoring_payload)\n",
    "print(\"Scoring result:\\n\" + json.dumps(scores, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clean\"></a>\n",
    "# 6. Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to clean up all created assets:\n",
    "- experiments\n",
    "- trainings\n",
    "- pipelines\n",
    "- model definitions\n",
    "- models\n",
    "- functions\n",
    "- deployments\n",
    "\n",
    "please follow up this sample [notebook](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Machine%20Learning%20artifacts%20management.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "# 7. Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You successfully completed this notebook! You learned how to use `ibm-watson-machine-learning-client` to run experiments. Check out our _[Online Documentation](https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html)_ for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Jan Sołtysik**, Intern in Watson Machine Learning.\n",
    "\n",
    "Modified by Bernard Beekman, IBM Federal and Public Sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
